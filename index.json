[{"categories":null,"contents":"","date":"Jun 24","permalink":"https://hearecho.github.io/projects/spider/","tags":null,"title":"Spider"},{"categories":null,"contents":"","date":"Jun 24","permalink":"https://hearecho.github.io/projects/web/","tags":null,"title":"Go-Web-Template"},{"categories":["论文阅读","算法","静态调度"],"contents":"论文 《Performance-effective and low-complexity task scheduling for heterogeneous computing 》\n 本文是异构平台的两种静态调度方法，分别是heft和cpop算法。\n 模型符号    符号 意义     $\\overline {w_i}$ 任务i的平均执行时间   $w_{i,j}$ 任务i在处理器j上的执行时间   $L$ 处理器通信模块启动时间   $L_m$ 处理器m的通信模块启动时间   $c_{i,k} = L_m + \\frac{data_{i,k}}{B_{m,n}}$ 任务i和任务j的通信时间   $B_{m,n}$ 处理器m，n的单位时间通信量   $data_{i,k}$ 任务i和任务j的通信量   $EST(n_i,p_j) = max{avail[j], max_{n_m\\in pred(n_i)} (AFT(n_m)+c_{m,j})}$ 任务i在处理器j上的最早启动时间   $EFT(n_i,p_j) = w_{i,j} + EST(n_i,p_j)$ 任务i在处理器j上的最早完成时间   $avail[j]$ 处理器j最早可用时间   $makespan = max{AFT(n_{exit})}$ dag的工作完成时间   $rank_u(n_i) = \\overline {w_i} + max_{n_j \\in succ(n_i)}(\\overline {c_{i,j}}+rank_u(n_j)) $ 作为权重   $rank_d(n_i) = max_{n_j \\in pred(ni)} {rankd(n_j) + \\overline {w_j} + \\overline {c_{j,i}}}$ 作为权重    算法 两个重要指标 $rank_{u}$  $rank_{u}$是从任务ni到出口节点关键路径的长度，是包括任务ni的计算耗时的。对于出口节点$rank_{u}$的值等于它的平均执行时间。\n $rank_{d}$  $rank_{d}$是从入口节点到任务ni的关键路径长度，不包括任务ni的执行时间，对于入口节点其$rank_{d}$的值等于0。\n heft算法  heft算法主要有两个阶段，第一个阶段计算所有任务的权重优先级，第二个阶段按照优先级顺序调度任务到最适合他们的处理器，以达到最小化任务的完成时间。\n 计算任务优先级  heft算法会将任务的优先度设置为$rank_u$，之后按照$rank_u$降低的顺序排列生成任务执行序列，如果两个任务的$rank_u$是相同的则可以有很多打破这种局面的策略，比如选择直接后继任务的$rank_u$更大的任务。最后生成的序列是一个拓扑排序所以肯定满足前序约束。\n 处理器选择  对于大多数调度算法，处理器的最早启动时间都是在该处理完成最后一个被分配任务之后。但是heft算法是考虑一个插入策略，考虑将任务插入到一个最早的空间时间间隔在两个已经完成调度的任务。空闲时隙时间的长度，即，在同一处理器上连续调度的两个任务的执行开始时间和完成时间之间的差异，应该至少能够满足计算要调度的任务的成本。并且必须要满足前置要求。\n 算法伪代码 1 2 3 4 5 6 7 8 9  # set the computation costs of tasks and communication costs of edges with mean values # Compute ranku for all tasks by traversing graph upward, starting from the exit task # Sort tasks in a scheduling list by noincreasing order of ranku values while there are unscheduled tasks in the list do: Select the first task ni from the list for scheduling for each processor pk in the processor-set (pk in Q) do: Comput EFT(ni,pk) value using the insertion-based scheduling policy Assign task ni to processor pj that minimizes EFT of task ni endwhile   cpop算法  cpop算法和heft算法结构相同都有两部分，不过使用的算法不相同。使用不同的属性设置任务的优先级以及不同的策略来选择最佳的处理器。\n 计算任务优先级  对于cpop算法需要将每个任务的$rank_u,rank_d$使用平均执行时间和平均通信时间进行计算。cpop算法使用dag的关键路径，路径的长度是沿着这条路径计算时间以及任务之间通信时间的总和。这条路径上所有计算时间总和是调度长度的下限（所有的任务都在同一个处理器上进行处理）。而每个任务的优先度是$rank_u,rank_d$的总和。入口的优先度等于关键路径的长度。对于平等的情况，选择第一个直系后继有更高的优先级的任务。具体选择在伪代码部分给出。\n 处理器选择  选择一个处理器作为关键路径专用处理器，这个处理器能够最小化执行时间。如果一个任务在关键路径上，直接调度到关键路径处理器。除此之外选择能够让该任务执行时间最短的其他处理器，注意不能调度到关键路径专用处理器。\n 算法伪代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  # set the computation costs of tasks and communication costs of edges with mean values # Compute ranku for all tasks by traversing graph upward, starting from the exit task # Compute rankd for all tasks by traversing graph downward, starting from the entry task # Compute priority(ni) = ranku(ni) + rankd(ni) for each task ni in the graph # SET_CP = {n_entry}, where SET_CP is the set of tasks on the critical path nk \u0026lt;- n_entry while nk is not the exit task do: Select nj where ((nj in succ(nk)) and (priority(nj)== |CP|)) SET_CP = SET_CP.append(nj) nk \u0026lt;- nj endwhile Select the critical path processor(p_cp) which minizes sum(w_i,j) Initialize the priority queue whith entry task while ther is an unscheduled task in the priority queue do: Select the highest priority task ni from priority queue if ni in SET_CP: Assign the task ni on p_cp else: Assign the task ni to processor pj which minimizes the EFT(ni,pj) Update the priority-queue with the sucessors of ni if they ready tasks endwhile   ","date":"Aug 31","permalink":"https://hearecho.github.io/post/heft%E7%AE%97%E6%B3%95-%E9%9D%99%E6%80%81%E8%B0%83%E5%BA%A6/","tags":["论文阅读","DAG","算法","静态调度"],"title":"HEFT算法 静态调度"},{"categories":["论文阅读","算法","动态调度"],"contents":"论文介绍 《Dynamic_scheduling_algorithm_for_parpllel_real_time_jobs_in_heterogeneous_system》\n 异构系统中并行实时作业的动态任务调度仍然是一些研究人员正在研究的具有挑战性的问题。但是基于DAG的实时任务调度还没有得到足够的重视。提出了一种基于DAG的实时任务调度模型和一种时间复杂度较低的实时调度算法DEFF。仿真实验表明，该调度模型和调度算法是可行的，在中小型并行作业的情况下，该算法可以获得较高的调度成功率\n 模型符号    符号 意义     $V$ 实时任务集合   $E$ 任务之间通信   $dl(v_i)$ 任务$v_i$的截至时间   $cv_i$ 任务$v_i$的计算量   $e_{i,j}=(v_i,v_j)$ 表示任务$v_i,v_j$之间的通信量   $P$ 处理器集合   $p_i$ 拥有本地存储的处理器   $C:V*P \\rightarrow R$ 表示不同的计算能力   $w_k$ 表示处理器$p_k$在单位时间内的计算量   $cv_i/w_k$ 表示任务$v_i$在处理器$p_k$上的计算时间   $M:E * P * P \\rightarrow R$ 表示异构通信能力。   $w_{km}$ 表示处理器$p_k,p_m$之间单位长度信息的传输时间   $w_{km}*e_{i,j}$ 表示$e_{i,j}$的传输时间   queue-Global Job Queue （GJQ） 全局作业队列，所有到达系统的任务首先都要进入这个队列中，然后再进入中心调度器。进入这个队列的是DAG任务   queue-Task Dispatch Queue (TDQ) 和中心调度器进行交互的，分解之后的dag子任务   Local Scheduling Queue (LSQ) 每个处理器拥有的本地任务队列   $at(p_k)$ 处理器$p_k$的最早空闲时间   $st_k(v_i)$ 实时任务$v_i$的最早开始时间   $ft_k(v_i)$ 映射到处理器$p_k$实时任务$v_i$的最早完成时间    调度算法 定义1  如果映射到处理器$p_k$实时任务$v_i$的最早完成时间$ft_k(v_i)$小于等于任务$v_i$的截至时间$dl(v_i)$，则实时任务$v_i$可以被调度到处理器$p_k$中。\n 定义2  映射到处理器$p_k$实时任务$v_i$的最早完成时间$ft_k(v_i)$被定义为:$$ft_k(v_i) = cv_i/w_k + max(st_k(v_i),at(p_k))$$\n 定义3  实时任务$v_i$的最早开始时间$st_k(v_i)$被定义为:$st_k(v_i)=max_{v_j\\in pred(v_i)}( ft_m(v_j+w_{mk}*e_{i,j}))$;其中$pred(v_i)$表示任务$v_i$的前一个集合。\n 算法实现 deff调度算法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72  \u0026#34;\u0026#34;\u0026#34; 论文算法实现 deff AST 本次deff调度算法启动的时间 AFT 上次deff调度算法结束的时间 DIFT 中间的插值 DIFT = AST-DIFT \u0026#34;\u0026#34;\u0026#34; import time import sys def deff(AFT, processors, tasks_dtq, tasks_scheduled, w, e, cp_w, deL_dag_tasks): \u0026#34;\u0026#34;\u0026#34; :param deL_dag_tasks: 无法进行调度的dag任务 :param cp_w: 处理器的计算能力一个数组 :param e: 表示任务之间的通信量，一个字典 e[task_i][task_j]表示两个任务之间的通信量 :param w: 表示处理器之间单位长度信息的传输时间 二维矩阵 :param tasks_scheduled: 已经被调度过的任务 :param tasks_dtq: dtq中的准备被调度的任务队列 :param AFT: 上次deff调度算法结束的时间 :param processors: 处理器数组，每个处理器元素都是一个字段储存处理器相关的信息 :return: \u0026#34;\u0026#34;\u0026#34; DIFT = time.time() - AFT for p in processors: if p[\u0026#39;at\u0026#39;] - DIFT \u0026lt; 0: p[\u0026#39;at\u0026#39;] = 0 else: p[\u0026#39;at\u0026#39;] -= DIFT for v in tasks_scheduled: if v[\u0026#39;ft\u0026#39;][v[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]] - DIFT \u0026lt; 0: v[\u0026#39;ft\u0026#39;][v[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]] = 0 else: v[\u0026#39;ft\u0026#39;][v[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]] = v[\u0026#39;ft\u0026#39;][v[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]] - DIFT while len(tasks_dtq) \u0026gt; 0: task = tasks_dtq[0] # 如果该子任务的其他任务已经存在不可调度的子任务 则直接舍弃 if task[\u0026#39;father\u0026#39;] in deL_dag_tasks: continue sps = [] for i in range(len(processors)): if len(task[\u0026#39;pred\u0026#39;]) \u0026gt; 0: max_st = -1 for pred_task in task[\u0026#39;pred\u0026#39;]: temp = pred_task[\u0026#39;ft\u0026#39;][pred_task[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]] + w[pred_task[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]][i] * e[task[\u0026#39;name\u0026#39;]][ pred_task[\u0026#39;name\u0026#39;]] if temp \u0026gt; max_st: max_st = temp task[\u0026#39;st\u0026#39;][i] = max_st else: task[\u0026#39;st\u0026#39;][i] = 0 task[\u0026#39;ft\u0026#39;][i] = task[\u0026#39;c\u0026#39;]/cp_w[i] + max(task[\u0026#39;st\u0026#39;][i], processors[i][\u0026#39;at\u0026#39;]) if task[\u0026#39;ft\u0026#39;][i] \u0026lt;= task[\u0026#39;dl\u0026#39;]: sps.append(processors[i]) if len(sps) \u0026gt; 0: min_p = None min_p_ft = sys.maxsize for p in sps: if task[\u0026#39;ft\u0026#39;][p[\u0026#39;index\u0026#39;]] \u0026lt; min_p_ft: min_p = p min_p_ft = task[\u0026#39;ft\u0026#39;][p[\u0026#39;index\u0026#39;]] task[\u0026#39;mapped_p\u0026#39;] = min_p min_p[\u0026#39;at\u0026#39;] = min_p_ft else: # 无法进行调度（也就是调度最后实时性不满足，直接舍弃） # 需要删除的是这个子任务所属dag任务的所有任务，但是不包括已经调度。 deL_dag_tasks.append(task[\u0026#39;father\u0026#39;]) # 我的做法是不在这里删除，只是将这个任务所属的dag任务加入到一个内存中进行存储 # 之后再进行再从gjq向tdq调度的时候进行判断 然后执行算法的时候进行判断不对他们进行调度即可 tasks_dtq = tasks_dtq[1:] # 返回算法结束时间 return time.time() pass   触发器算法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  \u0026#34;\u0026#34;\u0026#34; 论文调度器的触发算法实现 触发器的触发条件，一个新的dag任务图到达，或者是一个一个子任务完成则会调用触发器算法 调用触发器的时刻，当GJQ新到达一个dag任务或者是一个子任务完成了 GJQ 全局作业队列 TDQ 任务分发队列 \u0026#34;\u0026#34;\u0026#34; def trigger(completed_tasks, task, trigger_type, remain_tasks, TDQ, completed_job, GJQ): \u0026#34;\u0026#34;\u0026#34; :param GJQ: job队列 :param completed_job: 完成的并行任务 :param TDQ: :param remain_tasks: 剩余任务 :param trigger_type: 0 新job到达 1 任务完成 :param completed_tasks: 已经完成的子任务，字典格式，key为dag任务的图 :param task: 完成的任务或者是新到的dag任务的开头任务， :return: \u0026#34;\u0026#34;\u0026#34; if trigger_type == 0: # 将所有的入口任务都加进去 也就是没有前继的任务 for task in remain_tasks: if len(task[\u0026#39;pred\u0026#39;]) == 0: TDQ.append(task) # 从剩余任务中删除这个任务 remain_tasks.remove(task) else: if len(remain_tasks) == 0: # 任务完成 completed_job.append({task[\u0026#39;father\u0026#39;]: task[\u0026#39;ft\u0026#39;][task[\u0026#39;mapped_p\u0026#39;][\u0026#39;index\u0026#39;]]}) return completed_tasks.append(task) for task in remain_tasks: if len(task[\u0026#39;pred\u0026#39;]) == 0: TDQ.append(task) # 从剩余任务中删除这个任务 remain_tasks.remove(task) else: flag = True for pred_t in task[\u0026#39;pred\u0026#39;]: if pred_t not in completed_tasks: flag = False if flag: TDQ.append(task) # 从剩余任务中删除这个任务 remain_tasks.remove(task)   ","date":"Aug 22","permalink":"https://hearecho.github.io/post/deff/","tags":["论文阅读","DAG","算法","动态调度"],"title":"DEFF算法论文阅读"},{"categories":["论文阅读","算法"],"contents":"动态DAG调度综述  在异构系统中调度的核心问题是：由于异构系统中处理器的性能不尽相同，所以为了获得更高的性能。系统调度需要将应用程序的任务分配给合适的处理器，并对每个资源上的任务执行进行排序。给定一个有向无环图（DAG）建模的应用程序，调度问题处理的是在异构环境中映射每个任务以最小化执行时间（makspan）。\n 动态调度基础  动态调度，任务在到达时分配给处理器，调度决策必须在运行时做出。调度决策基于在运行时可能更改的动态参数。在动态调度中，任务可以在运行时重新分配给其他处理器。动态调度相比静态调度灵活且速度更快。由于我们异构系统处理同一个任务的时间是不相同的，所以我们每次调度的时候应该考虑将任务放在最合适的处理器中。\n 相关的DAG调度算法 Monte Carlo 算法  Stochastic DAG scheduling using a Monte Carlo approach\n该算法使用静态调度方法。主要目的是最大限度地缩短完工时间。该算法避免了适用于任意随机分布的随机变量的复杂计算。阈值用于优化调度。概率分布用于最小化完工时间。\n CBHD 算法  基于集群的复制权重，用于异构系统上任务的高效调度和映射，将程序分解为子任务，同时与其他任务一起工作[12]。该算法将三重聚类算法与HEFT算法相结合，将任务分为相互关联的组，并对每个簇中的任务进行排序，以提高负载均衡调度算法的性能。其主要目标是最小化执行时间，最大化处理器利用率和处理器之间的负载平衡。\n P-HEFT算法  P-HEFT（并行异构最早完成时间）的算法。该算法在不影响最大完工时间的前提下，以很高的效率处理异构集群中的并行任务。该算法的主要目标是最小化具有不同到达时间的作业的最大完工时间和批处理时间，从而在作业执行期间更改分配给作业的处理器(看描述也不是动态算法)\n High Performance and Energy Efficient Task Scheduling Algorithm  该算法关注调度长度和能量/功耗的最小化。该算法分为编译阶段和运行阶段。编译时间阶段有三个阶段，例如级别排序、任务优先级和处理器选择。在运行期间，为了节省能量，该算法将任务从繁忙节点重新调度到理想节点。该算法的性能明显优于传统算法。\n该算法为动态调度算法。\n Constrained Earliest Finish Time (CEFT) Algorithm  受约束的最早完成时间。这种新方法是使用受约束关键路径（CCPs）的概念为异构系统提供更好的调度。一旦发现DAG中的CCPs，任务将使用整个CCPs的完成时间进行调度。这种方法有助于以较短的完工时间生成时间表，并且工作复杂度很低。\n Sorted Nodes in Leveled DAG Division (SNLDD) Algorithm  该算法称为高性能任务调度算法。这种类型的算法将DAG划分为不同的级别，每个级别根据计算时间按降序排序，从而减少任务之间的依赖性。静态任务调度适用于处理器数量有限的异构系统。这种类型可能会产生高质量的任务调度。DAG中所有任务的计算时间只计算一次，因此消除了运行时开销。处理器的平滑时间也被最小化，因为DAG被调平并分配给处理器。\n Multi – Queue Balancing Algorithm  在功能单元中引入了调度概念。该算法具有各种类型的功能单元，不使用有限数量的硬件和软件。这种类型的算法称为离线非确定性算法。该算法的主要目标是最小化作业完成时间，根据资源的可用性将任务分配给机器，并最大限度地利用异构系统。每个任务都在其匹配的处理器上执行。也是静态调度算法。\n Clustering Scheduling Strategies Algorithm  以减少应用程序的配置数量和执行时间，同时提高现场可编程门路（FPGA）器件的利用率。在可重构计算系统中，引入启发式调度策略和动态规划调度策略，将有向无环图（DAG）划分为多个簇。\n SD-based Algorithm for Task Scheduling (SDBATS)  基于SD的算法是一种标准偏差方法，用于计算异构计算环境中可用资源上给定任务的预期执行时间。该算法将各种条件应用于标准任务图应用，如高斯消去和快速傅立叶变换应用。这种方法产生了高质量的计划，并产生了低成本的计划和系统效率。 可以用于动态调度算法。\n Online Scheduling of Dynamic Task Graphs  与传统方案相比，动态任务图的在线调度更为现实，任务图在运行时会发生变化，处理器间的通信也会固定数量。在线调度采用广播和点对点通信。该算法的主要目标是减少完工时间。\n Node Duplication Modified Genetic Algorithm Approach (NMGA)  该方法采用了顶层和底层方法。它展示了节点复制技术的效率。主要目的是最小化完成时间并增加系统吞吐量。复制任务以减少总时间。\n Heuristic based for Genetic Algorithm  该算法需要较少的计算时间[22]。该算法基于多处理器系统中的任务调度，通过选择合适的处理器来达到次优解。底层方法是通过选择合格的处理器来分配任务，以获得最小的完成时间。\n List based Heuristic Task Scheduling  该方法具有不同类型的任务优先级，以获得最小的调度长度和速度。这只继承静态调度，静态调度进一步分为作业调度和任务调度。该算法的主要目的是最小化执行时间和通信延迟，最大限度地提高资源利用率。\n Efficient Genetic Algorithm  该算法继承了定制的遗传算法，为HEDCS生成高质量的任务调度。新算法的性能由两种调度算法实现，即HEFT算法和DLS算法。这适用于随机生成的任务图和某些实际数值应用的任务图。该算法的主要目标是增加调度长度、加速比和效率。\n BNP Scheduling Algorithms  它将一个由边有向无环图（DAG）表示的并行程序引入一组同质处理器。主要目标是尽可能缩短完成时间。几类算法和一类调度的性能称为有界处理器数（BNP）。比较基于不同的调度参数，如最大完工时间、速度、处理器利用率和调度长度比。主要重点是增加处理器上的任务数量，以提高这些算法的性能\n Predict Earliest Finish Time (PEFT)  该算法具有相同的时间复杂度，即v任务和p处理器的时间复杂度为O（v2:p），在不增加与计算乐观代价表（OCT）相关的时间复杂度的情况下引入了一个特性。设计值是一个乐观的成本，因为计算中未测量处理器可用性。此算法仅基于用于对任务进行排序和处理器选择的OCT表。PEFT算法在调度长度比、效率和频率方面为异构系统执行基于列表的算法。\n Hybrid Genetic Scheduling Algorithm  该算法为每个任务分配一个耦合因子，并通过避免大量通信时间将其调度到同一处理器上。该算法的目标是通过将相互强耦合的任务调度到同一个处理器上来生成高质量的初始解，并通过使用耦合初始解、随机解、，通过交叉和变异算子中的列表调度算法获得近似最优解。\n Fork – Join Method (TSFJ)  该算法继承了多处理机系统中的任务调度，目的是最小化总执行时间，从而达到最大的速度和效率。应用程序由有向无环图（DAG）表示，任务根据fork-join结构分配给处理器。该算法的主要性能基于调度长度、加速效率和负载平衡。\n Non – Dominated Sorting Genetic Algorithm – II (NSGA-II)  该算法在异构多处理器系统上引入了调度应用程序，主要用于单一目的，如执行时间、成本或总数据传输时间。所提出的算法是利用进化技术开发一种多目标调度算法，用于在多处理器环境中调度一组依赖于可用资源的任务。主要目标是最大限度地缩短完工时间。\n Task Scheduling and Energy Conservation Techniques  该算法解决了多处理器系统中依赖任务的能量感知调度技术中的“最新技术”，以减少总体完工时间和能源消耗。\n Critical Path Scheduling with T – level (CPST)  在CPST中，使用任务的t级值生成基于关键路径的任务序列，其中使用基于方差的计算和通信成本。任务按优先级的非递增顺序排序和选择，并在处理器上调度，以优化各种性能指标。目标是将任务映射到合适的资源上，并最小化最大完工时间。\n Multi – Core Scheduling  引入异构协处理器（即一个处理器和多个异构协处理器）,处理器处理控制信号\u0026amp;异构协处理器用于数据计算，因为需要多个协处理器调度器来确定哪些子任务传输到哪个协处理器。该算法采用迁移策略来提高资源的利用率。\n Task Scheduling Algorithm using Merge Conditions  该算法在保留调度长度的同时减少了处理器数量。该算法根据条件找到合并对，并在不增加调度长度的情况下合并它们。函数用于查找最大对以减少合并次数。\n Linear Programming based Scheduling Algorithms  该算法应用于具有不同特征的五种不同应用中的各种邻近查询，并通过额外的计算资源有力地提高了性能。所提出的算法是为并行邻近计算而设计的，以最小化计算资源所花费的最大时间。\n Comparative Study of Scheduling Algorithm  一种称为调度算法比较研究的算法，用于在静态资源集上映射具有不同截止日期的多个工作流的任务。主要目的是将任务映射到处理器，最大限度地提高资源利用效率，同时满足所有工作流的最后期限。\n 算法比较以及未来提升    算法 目的 优点 未来提升方向     Monte Carlo based DAG scheduling approach 最大限度缩短完工时间 避免了随机变量的复杂计算，适用于人任何随机分布 动态调度   Clustering based HEFT with duplication 最小化执行时间 最大限度的提高处理器利用率和复杂平衡 更好的优化方法   P-HEFT 尽可能缩短完成时间 高效和最佳完成时间 多用户环境的优化   High performance and energy efficient task scheduling algorithm 最小化完成时间 调度长度和能量消耗 大规模任务图   Constrained Earliest Finish Time 最小化执行时间 明细表长度的最小阈值 用于在机器的后续操作中选择多条受约束的关键路径   Sorted Nodes in Leveled DAG Division 加速、效率、复杂性和质量 处理器的最小完成时间和最大利用率 在异构系统上调度更多作业   Multi Queue Balancing Algorithm 最大限度地缩短完成时间和最大限度地利用资源 处理器的最小完成时间和最大利用率 在异构系统上调度更多作业   Heuristic and Dynamic programming scheduling strategy 尽量减少执行时间 高度并行而不丧失通用性 热力性能   SD-Based Algorithm for Task Scheduling 时间表长度和速度 减少执行时间并分配任务优先级。 同质系统   Online Scheduling of Dynamic Task Graphs 使制造跨度最小化 固定通道数的处理器间通信 离线   Node duplication Modified Genetic Algorithm Approach 使完成时间和吞吐量最小化 复制任务以减少总时间 非确定性同质系统   Heuristic based for genetic algorithm 使制造跨度最小化 通过选择合格的处理器来分配任务的底层方法 非确定性同质系统   List based heuristic task Scheduling 执行时间、通信延迟和最大化资源利用率 并行架构的效率。任务执行时间、通信成本和任务相关性在执行前可用。 动态调度   An Efficient Genetic Algorithm 调度长度、加速和效率。  异构处理器的部分连接网络。   BNP Scheduling Algorithms 尽可能缩短完成时间 在性能上增加任务和处理器的数量 异构系统   Predict Earliest Finish Time 使制造跨度最小化 调度长度比率、效率和频率 异构系统   A Hybrid Genetic Scheduling Algorithm 将任务分配给可用的处理器并生成跨度 避免过多的沟通时间。通信成本长，更有效，图形结构更灵活 更好的优化方法   Fork-Join Method 以最小化总执行时间 调度长度、加速比、效率和负载平衡 更多节点数。   Non-dominated sorting Genetic Algorithm-II 使完工时间和可靠性成本最小化 用于在最短时间内选择最佳计划 动态调度   Task Scheduling \u0026amp; Energy Conservation Techniques 减少总完工时间和能源消耗 高性能计算系统用途广泛，性能价格低廉，能耗巨大。 异构系统是一组关于不同任务图特征的随机和随机集合。   Critical path scheduling with t-level 最小化总体执行时间和最大完工时间 任务按其优先级的非递增顺序排序和选择 同质系统   Multi-core Scheduling 尽量缩短响应时间，提高资源利用率 它使用调度机制来调度不同的子任务和迁移策略，以减少响应时间 同质系统   Task Scheduling Algorithm using Merge Conditions 要最小化时间表长度 减少合并的次数。 预处理调度方法   Scheduling in Heterogeneous Computing Environments for Proximity Queries 在异构计算系统中最小化最大完工时间和邻近计算 鲁棒性强，专为并行邻近计算而设计 针对更多种类作业的最佳优化方法   Comparative study of scheduling algorithm 最大限度地提高资源利用效率 提高效率，按时完成任务。 动态和电子科学基础设施平台    ","date":"Aug 22","permalink":"https://hearecho.github.io/post/surver-dynamic-dag-schedule/","tags":["论文阅读","DAG","算法"],"title":"Surver Dynamic Dag Schedule"},{"categories":["论文阅读","算法"],"contents":"论文简介 《Runtime Parallel Incremental Scheduling of DAGs》\n这篇论文主要是提出一种并行增量的DAG调度方法。主要学习一下这篇论文关于动态调度DAG任务方面的内容。因为之前主要用的最多的静态调度方法就是HEFT与CPOP。所以想通过这篇文章，看是否可以将动态思路运用到HEFT或者CPOP中。本篇论文仍然是针对一个DAG图进行调度。并未给出针对多DAG图的相关思路。\n论文出发点 本篇论文出发点是从当前DAG调度算法的缺点出发的，主要列举出五点，分别是：\n 因为它们在单处理器机器上运行，所以速度很慢。调度程序可能需要现代工作站数十小时的计算时间来生成1K处理器的调度计划。 它们需要很大的内存空间来存储图形，并且此后无法扩展。例如，要将并行程序调度到1K处理器，数百万个节点的图形可能需要数百MB的内存空间。 获得的计划的质量在很大程度上依赖于对执行时间的准确估计。没有这些信息，复杂的调度算法就无法提供令人满意的性能。 应用程序必须针对不同的问题大小重新编译，因为任务数量和每个任务的估计执行时间随问题大小而变化。 它是静态的，因为编译时必须知道DAG中任务的数量和任务之间的依赖关系。因此，它不能应用于动态问题。  论文概述 静态动态调度系统的区别 在静态系统中，DAG由用户程序生成，并在编译时调度。然后将计划的DAG加载到PEs以执行。在运行时调度系统中，DAG不是一次生成的。相反，它是增量生成的。为此，在编译时生成一种紧凑形式的DAG（紧凑DAG或CDAG）。然后在运行时将其增量扩展到DAG。CDAG的大小与程序大小成正比，而DAG的大小与问题大小或矩阵大小成正比。\n增量执行模型 在增量执行模型中，每个系统阶段只调度一个子图。每次生成的子图的大小通常受到可用内存空间的限制。系统调度活动与基础计算工作交替进行。它从一个系统阶段开始，在此阶段仅生成和调度DAG的一部分。然后是用户计算阶段，以执行计划任务。PEs将执行，直到大多数任务完成，并转移到下一个系统阶段，以生成和安排DAG的下一部分\n策略决定何时从用户计算阶段转移到下一个系统阶段。当任何PE的任务用完时，都会触发该事件。PE通过向所有其他PE广播暂停信号来启动调度活动。PE在接收到暂停信号后，完成当前任务的执行，并从该用户阶段切换到下一个系统阶段。在下一个系统阶段，将生成DAG的另一部分。新生成的任务与旧任务一起调度。这样，可以容忍由于估算不准确而导致的负载不平衡。然后将计划任务发送给PEs，以开始下一个用户阶段。\n并行调度算法 由于动态调度算法，需要实时进行调度，所以我们应该找到，调度时间和任务执行时间之和最短的算法。\nALAP(as-laste-as-possible):一个节点的尽可能晚的时间定义为$T_L(n_i) = T_{critical}-level(n_i)$，其中$T_{critical}$是计算节点和边权重的关键路径长度。$level(n_i)$​是当前节点到最后节点的最长路径的长度，包括当前节点。\nPPE:执行调度算法的PE\nTPE:执行任务的目标PE\nMCP算法  计算每个节点的ALAP时间 按递增的ALAP顺序对节点列表进行排序。通过使用后继节点的最小ALAP时间、后继节点的后继时间等来断开连接 将列表中的第一个节点调度到允许最早开始时间的PE。从列表中删除节点并重复步骤3，直到列表为空。  作者通过使用MCP算法的非插入版本来进一步降低复杂性。它的复杂度是$O(e+nlogn+np)$​​，其中e是边的个数，p是PEs的个数，n是图中的节点数。作者的实验表明，对于粗粒度划分，该算法产生的调度长度最多比原始MCP长3%，但其调度时间减少了一到两个数量级。\n水平并行MCP算法（HPMCP） 图形分区后，每个PPE使用MCP调度其分区以生成其子调度。在应用MCP时，我们忽略了分区之间的依赖关系，因此每个分区都可以独立调度。如果一个节点的所有父节点都不是本地节点，则该节点在其分区中被视为入口节点。节点按其ALAP优先级的顺序进行调度。每个PPE从其本地时间0开始调度其分区。然后连接相邻的子调度以形成最终调度。如下图所示：\n 对节点进行分区，每个分区分配给一个PPE 每个PPE将MCP算法应用于其分区以生成子调度，忽略节点与其远程父节点之间的边缘。将列表中的第一个节点安排到允许最早启动时间的TPE。从列表中删除节点并重复此计划步骤，直到列表为空。 连接每对相邻的子表。  系统概览 作者提出的运行时系统主要包括DAG图形生成、调度、节点执行、通信处理和增量执行处理模块。\nDAG图形生成 在系统阶段k，新扩展的节点和上阶段未执行的节点集。生成的DAG子图$G_k = {S_k,E_k}$​。如果节点$n_i，n_j$​都在节点集合$S_k$​中那么$e_{i,j}$​是$E_k$​中的一条边。如果目标节点不在$S_k$​中，则来自$S_k$​中节点任何传出边缘将成为*future message*。之后子图$G_k$将会被安排到PE中，并在用户阶段k执行。\n调度 调度模块将为$S_k$中的每个节点建立从其逻辑ID到其物理ID的映射，该物理ID由目标PE编号和目标PE处的本地ID组成。对于每个在$E_k$中的边$e_{i,j}$，节点$n_i$拥有节点$n_j$的物理ID。因此，当节点i执行完成时，其所有传出消息可以立即定向到其目的地。一旦PPE生成其节点子集，它将使用MCP算法独立地调度这些节点以形成子调度。一个已经被调度的DAG会被加载到TPEs中执行，每个TPE获得一个按执行顺序排序的节点列表（使用本地ID）。\n执行 在执行模块中，调度例程负责选择节点并准备执行。在被调度的DAG中，列表中的节点将按顺序执行。分派例程选择列表中的下一个节点并检查其传入消息。当所有传入消息到达后，节点就准备就绪并执行。分派例程为节点的执行分配内存并准备参数。然后调用节点过程。节点执行完成后，通信处理模块处理输出参数。为节点分配的所有内存空间也将被释放。这种消息驱动的宏数据流执行模型可以有效地利用内存。\n通信处理 当PE没有准备好执行的节点时，或者在一个节点执行完成和下一个准备好的节点执行开始之间的时间段内，处理消息接收。由于推送方案应用于包含其目的地PE号码以及本地ID的每个传出消息，因此到达的消息可以容易地附加到相应的节点。一旦所有传入消息到达，节点本身就可以执行了。节点执行后，将为每个传出边缘发送一条消息。如果消息只有一个目的地，则将其分类为单播。如果消息具有多个回执，则将其分类为多播。尽管多播消息可以逐个发送到不同的目的地，但它可能需要不可接受的通信时间。通信模块使用多播树进行有效的多播\n增量执行处理 接收到暂停消息的每个PE将完成当前节点执行并暂停其当前用户阶段k。在进入系统阶段k+1之前，需要处理尚未执行的剩余节点以及相应的消息，以将其合并到阶段k+1中。在进入阶段k+1之前，必须使节点逻辑ID到其物理ID的当前映射无效，因为物理ID仅对特定阶段有意义。当剩余节点被发送回重新调度时，已经到达这些节点的消息被分离并转换为将来要附加到阻塞队列中的消息，以便延迟这些消息的传递，直到新映射可用于阶段k+1。如果该消息是多播消息，它将被删除，因为多播消息将在以后的每个阶段重新广播。（多播消息是每个阶段都会广播一次，而单播之后发送一次，所以需要进行保存，防止节点未执行，重新分配之后，不能收到消息）\n","date":"Aug 08","permalink":"https://hearecho.github.io/post/runtime_parallel_incremental_scheduling_of_dags%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/","tags":["论文阅读","DAG","算法"],"title":"Runtime_Parallel_Incremental_Scheduling_of_DAGs论文阅读"},{"categories":["论文阅读","EDF","DAG","算法"],"contents":"论文阅读 《A Stretching Algorithm for Parallel Real-time DAG Tasks on Multiprocessor Systems》\n本篇论文的算法属于静态调度算法，预先知道DAG图，然后根据DAG图转换为MTS。再在MTS的基础上对整个任务进行拉伸。也就是本文提出的全局拉伸算法。\n本文的贡献  提出了一种适用于DAG任务模型的拉伸算法。该算法是DAG调度过程的前一步（静态调度）。将并行的DAG转换为独立的舒徐线程，其他无法进行转换，或者转换之后超出时间的则在其他处理器并行执行。 对于在m个相同处理器平台上执行的由n个DAG任务组成的任务集合，作者证明了扩展任务的全局EDF调度具有相同的资源扩充界限:$\\frac{3+\\sqrt{5}}{2}$，在$n\u0026lt;\\varphi*m^{'}$，其中$m^{'}\u0026lt;=m$，是除了主线程之外的其他线程的数量，而$\\varphi$是黄金分割率。  文章中参数的含义    参数名 含义     ${t_{i,j} 1\u0026lt;=j\u0026lt;=n_i}$   $G_i$ 子任务之间的依赖关系   $O_i$ DAG任务的偏移量   $D_i$ DAG任务的相对截至时间   $T_i$ 连续任务之间的间隔时间，一般看作$T_i=D_i$   $C_{i,j}$ 单个子任务任务的最坏执行情况所用的时间   $C_i = \\sum_{j=1}^{n_i}C_{i,j}$ 单个DAG任务的最坏执行情况所用的时间   $U_i=\\frac{C_i}{T_i}$ 利用率，最坏运行情况在限制时间内多少   $Li$ DAG图中所有路径中执行时间最长的路径所用的时间   $Sl_i = D_i-L_i$ 执行最长路径之后剩余的时间。   $S_i$ 转换为MTS形式之后，段的总数。   $e_{i,j}$ 每个段的最长执行时间，按这个段中所有子任务最短的计算。   $m_{i,j}$ 每个段中任务的数量   $MTS L_i = \\sum_{j=1}^{s_i}e_{i,j}$ MTS模式下的关键路径的长度   $MTSC_i = \\sum_{j=1}^{s_i}m_{i,j}*e_{i,j}$ MTS模式下的最坏情况执行时间   $ f_i = \\frac{Sl_i}{C_i-L_i}=\\frac{D_i-L_i}{C_i-L_i}\u0026lt;=\\frac{D_i}{C_i}\u0026lt;1 $ 分发参数   $f_{i,j} = f_i*(m_{i,j}-1)$ 要添加到主线程的段$S_{i,j}$中的线程数   $D_{i,j} = (1+f_{i,j})*e_{i,j}$ 每段$S_{i,j}$的中间截止日期$D_{i,j}$   $O_{i,j}=\\sum_{k=1}^{j-1}D_{i,k}$ 每个段的偏移量    任务模型 文章提出的任务模型就是DAG集合，其中每个DAG任务使用$({t_{i,j}|1\u0026lt;=j\u0026lt;=n_i},G_i,O_i,D_i)$来进行表示，其中$t_{i,j}$表示任务$T_i$的每个子任务，而$G_i$表示各个子任务之间的依赖关系，$O_i$表示整个任务的偏移量，而$D_i$表示任务的相对截至时间。\n任务集如果想在m个处理器使用任何调度算法进行调度，则需要满足下面两个条件。 $$ \\forall{t_i}\\in{T},L_i\u0026lt;D_i \\\nU(T) = \\sum_{i=1}^{n}U_i = \\sum_{i=1}^{n}\\frac{C_i}{T_i}\u0026lt;=m $$\nDAG拉伸算法 我们结合文中给出的示例来说明文章中提出的算法。\n图中我们可以获得的信息就是路径总共有六条可执行路径，分别是{1，4，6}，{1，4，7}，{2，4，6}，{2，4，7}，{3，6}，{5，7}。则L = 6，也就是主路径的情况。\n这是转换为MTS之后的形式。我们根据依赖关系和主路径，将子任务转换为MTS形式。其中如果DAG图的利用率小于1，证明整个任务可以在一个处理器中顺序执行，所以只有当利用率大于1的时候才会将DAG图转换为MTS形式。从图中我们可以看出总共有5段，每段的任务数量不相同。如第一段，由于任务3，5的最坏执行时间都是2，所以第一段的$e_{i,j}$也为2。后续同理。\n转换为MTS之后，最重要的就是计算每个段有几个线程可以加入到主线程中，也就是$f_{i,j}$的计算。\n转换结果如上图。整个算法流程如此，所以整个来说，这个就是一个静态的调度算法。\n","date":"Jun 30","permalink":"https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-edf/","tags":["论文阅读","EDF","DAG","算法"],"title":"论文阅读 EDF"},{"categories":["面试","redis"],"contents":"Redis 1.简介 Redis是一种非关系型（NoSQL）内存键值数据库，可以存储键和五种不同类型的值之间的映射。\n键的类型只能为字符串，保证不可变性，值的类型只有五种：字符串、列表、集合、哈希表、有序集合。\nRedis面试问题的主要出发点：数据类型、跳表、缓存、持久化、数据淘汰策略。\n2.数据类型    数据类型 可以存储的值 操作     STRING 字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作，对整数和浮点数执行自增或者自减操作   LIST 列表 从两端压入或者弹出元素 ，对单个或者多个元素进行修剪， 只保留一个范围内的元素   SET 无序集合 添加、获取、移除单个元素， 检查一个元素是否存在于集合中， 计算交集、并集、差集， 从集合里面随机获取元素   HASH 包含键值对的无序散列表 添加、获取、移除单个键值对， 获取所有键值对，检查某个键是否存在   ZSET 有序集合 添加、获取、删除元素，根据分值范围或者成员来获取元素， 计算一个键的排名    3.数据结构 字典 字典是HASH的底层结构，是一种散列表结构，使用的是拉链法解决哈希冲突。Redis 的字典 dict 中包含两个哈希表 dictht，这是为了方便进行 rehash 操作。在扩容时，将其中一个 dictht 上的键值对 rehash 到另一个 dictht 上面，完成之后释放空间并交换两个 dictht 的角色。有点类似于CopyandWriteList中扩容的操作。rehash 操作不是一次性完成，而是采用渐进方式，这是为了避免一次性执行过多的 rehash 操作给服务器带来过大的负担。\n跳表 是有序集合的底层实现之一。跳跃表是基于多指针有序链表实现的，可以看成多个有序链表。在查找时，从上层指针开始查找，找到对应的区间之后再到下一层去查找。\n与红黑树等平衡树相比，跳跃表具有以下优点：\n 插入速度非常快速，因为不需要进行旋转等操作来维护平衡性； 更容易实现； 支持无锁操作。  4. redis使用场景    使用场景 详细     计数器 可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。   缓存 一般和关系型数据库进行配合，将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。   查找表 例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了 Redis 快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源   消息队列 List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息   会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。   分布式锁 利用SETNX实现分布式锁，或者是ReadLock实现分布式锁。    5.键的过期时间 Redis 可以为每个键设置过期时间，当键过期时，会自动删除该键。\n对于散列表这种容器，只能为整个键设置过期时间（整个散列表），而不能为键里面的单个元素设置过期时间。散列表算作值。\n6.数据淘汰策略 因为我们的内存是有限的，所以对于部分数据我们总会要实行内存淘汰策略，以免超出内存发生大小。\nRedis具体有6中淘汰策略：\n   策略 描述     volatile-lru 从已设置过期时间的数据集中挑选最近最少使用的数据淘汰   volatile-ttl 从已设置过期时间的数据集中挑选将要过期的数据淘汰   volatile-random 从已设置过期时间的数据集中任意选择数据淘汰   allkeys-lru 从所有数据集中挑选最近最少使用的数据淘汰   allkeys-random 从所有数据集中任意选择数据进行淘汰   noeviction 禁止驱逐数据    使用 Redis 缓存数据时，为了提高缓存命中率，需要保证缓存数据都是热点数据。可以将内存最大使用量设置为热点数据占用的内存量，然后启用 allkeys-lru 淘汰策略，将最近最少使用的数据淘汰。\nRedis 4.0 引入了 volatile-lfu 和 allkeys-lfu 淘汰策略，LFU 策略通过统计访问频率，将访问频率最少的键值对淘汰。\n一般情况下还是使用前三种最好，因为不设置过期时间可能确实这些数据比较重要。\n7.持久化 Redis 是内存型数据库，为了保证数据在断电后不会丢失，需要将内存中的数据持久化到硬盘上。\nRDB 持久化 将某个时间点的所有数据都存放到硬盘上。\n可以将快照复制到其它服务器从而创建具有相同数据的服务器副本。\n如果系统发生故障，将会丢失最后一次创建快照之后的数据。\n如果数据量很大，保存快照的时间会很长。\n持久化 将写命令添加到 AOF 文件（Append Only File）的末尾。\n使用 AOF 持久化需要设置同步选项，从而确保写命令同步到磁盘文件上的时机。这是因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区，然后由操作系统决定什么时候同步到磁盘。有以下同步选项：\n   选项 同步频率     always 每个写命令都同步   everysec 每秒同步一次   no 让操作系统来决定何时同步     always 选项会严重减低服务器的性能； everysec 选项比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器性能几乎没有任何影响； no 选项并不能给服务器性能带来多大的提升，而且也会增加系统崩溃时数据丢失的数量。  随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令。大致思路是将redis文件中所有的数据作为插入指令重新写入一个文件中，之后将以前文件丢弃即可。以后的命令都写入新的AOF文件。\n8.哨兵机制 Sentinel（哨兵）可以监听集群中的服务器，并在主服务器进入下线状态时，自动从从服务器中选举出新的主服务器。\n9. 缓存问题 缓存穿透 指的是对某个一定不存在的数据进行请求，该请求将会穿透缓存到达数据库。\n解决方案：\n 对这些不存在的数据缓存一个空数据； 对这类请求进行过滤  缓存雪崩 指的是由于数据没有被加载到缓存中，或者缓存数据在同一时间大面积失效（过期），又或者缓存服务器宕机，导致大量的请求都到达数据库。\n在有缓存的系统中，系统非常依赖于缓存，缓存分担了很大一部分的数据请求。当发生缓存雪崩时，数据库无法处理这么大的请求，导致数据库崩溃。\n解决方案：\n 为了防止缓存在同一时间大面积过期导致的缓存雪崩，可以通过观察用户行为，合理设置缓存过期时间来实现； 为了防止缓存服务器宕机出现的缓存雪崩，可以使用分布式缓存，分布式缓存中每一个节点只缓存部分的数据，当某个节点宕机时可以保证其它节点的缓存仍然可用。最好的解决方案。增加了系统的高可用性。 也可以进行缓存预热，避免在系统刚启动不久由于还未将大量数据进行缓存而导致缓存雪崩。  缓存一致性 缓存一致性一般就是redis数据库和mysql数据库之间在更新和删除时候的问题。其实一般情况下设置过期时间，一段时间之后缓存中数据都会消失，但是就怕在过期时间内又缓存更新的情况。\n先更新数据库，然后再立即去删除缓存。再读缓存的时候判断缓存是否是最新的，如果不是先进行更新。\n每日一题 在一个 2 x 3 的板上（board）有 5 块砖瓦，用数字 1~5 来表示, 以及一块空缺用 0 来表示.\n一次移动定义为选择 0 与一个相邻的数字（上下左右）进行交换.\n最终当板 board 的结果是 [[1,2,3],[4,5,0]] 谜板被解开。\n给出一个谜板的初始状态，返回最少可以通过多少次移动解开谜板，如果不能解开谜板，则返回 -1 。\n 遇到这种问题基本很多都是广度优先搜索，这些可以将二维数组转换为1维。按照行优先的顺序给2×3 的谜板进行编号。因此，我们在 status 中找出 00 所在的位置 x，对于每一个与 x 相邻的位置 y，我们将 status[x] 与 status[y] 进行交换，即等同于进行了一次操作。就是对位置进行标号，找出位置的相邻关系，然后进行广度优先搜索。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  var neighbors = [6][]int{{1, 3}, {0, 2, 4}, {1, 5}, {0, 4}, {1, 3, 5}, {2, 4}} // 这种最少通过多少次变换，很多都是使用广度优先搜索 func slidingPuzzle(board [][]int) int { const target = \u0026#34;123450\u0026#34; s := make([]byte, 0, 6) for _, r := range board { for _, v := range r { s = append(s, \u0026#39;0\u0026#39;+byte(v)) } } start := string(s) if start == target { return 0 } // 枚举 status 通过一次交换操作得到的状态  get := func(status string) (ret []string) { s := []byte(status) x := strings.Index(status, \u0026#34;0\u0026#34;) for _, y := range neighbors[x] { s[x], s[y] = s[y], s[x] ret = append(ret, string(s)) s[x], s[y] = s[y], s[x] } return } type pair struct { status string step int } q := []pair{{start, 0}} seen := map[string]bool{start: true} for len(q) \u0026gt; 0 { p := q[0] q = q[1:] for _, nxt := range get(p.status) { if !seen[nxt] { if nxt == target { return p.step + 1 } seen[nxt] = true q = append(q, pair{nxt, p.step + 1}) } } } return -1 }   参考资料  CsNotes 缓存数据库更新  ","date":"Jun 26","permalink":"https://hearecho.github.io/post/redis%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/","tags":["面试","redis"],"title":"Redis面试问题"},{"categories":["论文阅读","算法"],"contents":"论文简介 《A new DAG based dynamic task scheduling algorithm (DYTAS) for multiprocessor systems》\n论文提出一种基于有向无环图（DAG）的动态任务调度算法。关注点主要是通过多处理系统，进行并行处理任务。主要关注点在于多处理器系统，并行。在多处理器系统中实现高性能是调度并行任务的关键因素。而动态任务调度的目标是将并行任务映射到多处理器上，并对执行顺序进行排序。\n本文旨在建立一个基于DAGs的动态调度模型。在该模型中，一个被分配的处理器称为中心调度器，负责动态地调度任务。在提出的动态调度模型的基础上，提出了一种新的动态调度算法。该算法在仿真环境下进行了实验，实验结果表明，所提出的调度算法是一种有效的动态调度算法，具有更好的性能。\n 我们常说的对于有向无环图最短执行时间的拓扑排序算法是在单处理器上进行运行的，任务是按照排序好的序列进行执行。\n DAG介绍 有向无环图(DAG) G = (V, E)，其中V是v个节点/顶点的集合，E是e个有向边的集合。边缘的源节点称为父节点，而汇聚节点称为子节点。没有父节点的节点称为入口节点，没有子节点的节点称为出口节点。\n相关工作 很多动态调度算法是为了支持实时系统进行设计的。实时系统是指系统的性能不仅取决与逻辑计算结果，而且还取决于结果产生的时间。\n调度算法分为静态调度算法和动态调度算法。\n 静态调度算法：任务的分配是离线进行的，即在实时任务正式在处理机上调度执行前，先把任务在处理机上的分配和调度时间安排好,在任务正式开始执行后按照预先的调度方案执行。这种调度方法主要用于周期任务的调度，它的优点在于能够预先安排好调动，减少任务调度过程中的开销;而缺点在于缺乏灵活性，在实际的调度中不能够及时地根据系统资源和任务的执行情况进行及时的调整。 动态调度算法：在实时系统中，很多任务并非都以周期方式在处理机上进行调度，更多任务，特别是非周期任务都是随机到达系统并动态调度执行的。在动态调度方法中，任务的分派和可调度性测试都是在系统运行时在线进行的。这种情况下，可调度性测试实际上变成了一种接受测试(acceptance test), 测试动态到达任务的截止期是否会被保证，如果无法保证任务的截止期，任务将被拒绝调度。可以看出，动态调度与静态调度相比有更好的灵活性，然后由于可调度性测试需要在线进行，它的调度算法的复杂度不能太高，并且由 于无法保证是否可以被调度，算法的可预测性(predictability)很差。也就是说动态调度算法主要算法是在线测试预估任务是否可以满足。  系统模型 负载模型 并行任务采用DAG建模。非实时DAG[7]定义为：G=（V，E），其中V是一组v个节点，E是一组w条有向边。DAG中的一个节点表示一个任务，而这个任务又是一组指令，这些指令必须在同一个处理器中顺序执行而不被抢占。节点ni的权重称为计算成本，用w（vi）表示。DAG中的边，每个边用（vi，vj）表示，对应于节点之间的通信消息和优先约束。边的权重称为边的通信开销，用c（vi，vj）表示。\n我们的系统看作有一组处理器组成，P={P1，P2，P3，…Pm}，其中Pi表示具有本地存储器的处理器。处理器之间是也是具有通信开销的。\n调度器模型 如下图所示，描述的是一个同构环境中一个新的非实时调度器模型。当所有并行任务到达一个被指定的中央调度器时，他将进入一个称为初始任务队列（ITQ）的队列，等待被调度；除了ITQ之外，还管理着两个队列：调度任务队列（DTQ）和完成任务队列（CTQ）。封装在调度器中的调度算法开始与ITQ一起工作。中央调度器负责调度DTQ中的每个就绪任务。一旦调度算法启动，所有的任务都会根据其依赖的任务进行安排。在安排任务之后，调度器将任务安排到单个处理器任务队列（PTQ）。处理器将在自己的PTQ中通过同时检查CTQ中的依赖任务结果来完成任务。如果CTQ没有利用其相关任务的结果，则PTQi应指向下一个PTQi+1、PTQi+2、…PTQn、PTQ1、…PTQi-1以确定合适的任务，并将该任务迁移到PTQi。在PTQi变空之前，调度算法应停止工作。Processor Status Window（PSW）显示处于运行状态和空闲状态的每个处理器的状态。\n动态调度算法-DYTAS 基于上述的调度模型，提出了一种新的动态调度算法。ITQ中的任务是通过依赖关系进行调度的。该算法首先对于ITQ中的前面的任务进行调度，并将其映射到处理器上。而在静态调度算法中，由于DAG的数据是预先知道的，所以任务是按一定的优先级排序的。但是，本文提出的动态调度算法不同于静态调度算法，它在运行时迁移任务。\nDYTAS算法的核心是处理器的选择策略，也就是对于任务的迁徙。主要取决于如何选择任务映射到的处理器，即使任务被调度得更早。\n当从PTQ集合中中选择处理器来执行特定任务时，必须考虑两个时间索引：\n 处理器Pi的最早空闲时间 处理器Pi上任务vi的最早开始时间。  在所提出的调度模型中，ITQ中的并行任务和就绪任务都在处理器的PTQ中。即使ITQ和DTQ位于中央调度器上，实际执行映射任务的处理器也与调度器分离并放置在PTQi处。同时，调度过程和执行过程是并行的。因此，调度器和工作处理器之间是同步的。\n 该论文算法有点问题，没有讲清楚部分参数的含义。给出的cc参数不知道是什么意思。不知道为啥引用还那么多。\n 算法简单解释 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  Procedure DYTAS # 这个部分是对整个任务进行拓扑排序 dtq[ ] = SORT[Ti , Tj] l = 0; # 将排序好的任务放置在各个不同ptq也就是处理器本地存储队列 while (dtq[ ] is not empty) do for i = 1 to n ptqi = dtq [l] l = l + 1 end for; end while; for each processor Pk in processor group do # 对每个处理器状态进行检查，如果处理器在运行，则选择下一个处理器队列 while (Pk is in running state) skip and select the next ptqk+1 end while Pk = ptqk[j] # 如果这个任务的前置任务已经完成，并且有处理器空闲，则执行任务 if (dependent task of ptqk[j] is in ctq) TASK(ptqk[ ],Pk , j, ctq, cpk, CTj) else # 否则的话，就是将指针指向下一个ptq队列判断，下一个队列同样位置上的任务是否可以执行。算法的关键就在这个部分 # 关键在于在执行的时间迁移任务。 do move the pointer to the next ptq if (dependent task of ptqk[j] is in ctq) TASK(ptqk[ ],Pk , j, ctq, cpk, CTj) exit do endif while(checking with all ptq’s once) endif end for end DYTAS Procedure for TASK # 任务执行 procedure TASK(ptqk[ ],Pk,j,ctq,cpk,CTj) do Tj with Pk remove Tj from ptqk insert Tj in ctq cpk = cpk + Ctj end TASK   实验 实验数据  cp是任务执行时间，cc不清楚是什么，也没说。\n  经过拓扑排序之后，装配在ptq中的任务仿真图。拓扑排序结果是有很多种结果的。但是不影响算法运行。\n  ！！！重要的运行时间迁移任务\n  结果展示，单处理器中的调度长度是240个时间单位。在第一个处理器（P1）中完成任务所用的时间是80个时间单位，P2是65个时间单位，P3是67个时间单位，P4是66个时间单位。\n ！！！论文意义不是很大，不清楚为什么那么多引用这篇文章的。\n每日一题 你有一个带有四个圆形拨轮的转盘锁。每个拨轮都有10个数字： \u0026lsquo;0\u0026rsquo;, \u0026lsquo;1\u0026rsquo;, \u0026lsquo;2\u0026rsquo;, \u0026lsquo;3\u0026rsquo;, \u0026lsquo;4\u0026rsquo;, \u0026lsquo;5\u0026rsquo;, \u0026lsquo;6\u0026rsquo;, \u0026lsquo;7\u0026rsquo;, \u0026lsquo;8\u0026rsquo;, \u0026lsquo;9\u0026rsquo; 。每个拨轮可以自由旋转：例如把 \u0026lsquo;9\u0026rsquo; 变为 \u0026lsquo;0\u0026rsquo;，\u0026lsquo;0\u0026rsquo; 变为 \u0026lsquo;9\u0026rsquo; 。每次旋转都只能旋转一个拨轮的一位数字。\n锁的初始数字为 \u0026lsquo;0000\u0026rsquo; ，一个代表四个拨轮的数字的字符串。\n列表 deadends 包含了一组死亡数字，一旦拨轮的数字和列表里的任何一个元素相同，这个锁将会被永久锁定，无法再被旋转。\n字符串 target 代表可以解锁的数字，你需要给出解锁需要的最小旋转次数，如果无论如何不能解锁，返回 -1 。\n 题目中问的是最小拨动次数，对应图中两者之间的最短路径，所以这种类型的题大多都广度优先搜索，因为有四个位置，并且每次拨动都有两种选择。而对于已经搜索过的图将不会再次搜索。对于每次的字符串他的下一个变化的字符串有八个。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  func openLock(deadends []string, target string) int { step := -1 queue := make([]string, 0) visited := make(map[string]bool, 0) for i := 0; i \u0026lt; len(deadends); i++ { visited[deadends[i]] = true } if _, ok := visited[\u0026#34;0000\u0026#34;]; ok { return -1 } queue = append(queue, \u0026#34;0000\u0026#34;) for len(queue) != 0 { size := len(queue) //没过一层就要步数加1，刚开始的0000不算在内 \tstep++ for i := 0; i \u0026lt; size; i++ { cur := queue[i] //当前字符串与目标字符串相同则return \tif cur == target { return step } //取出现在的队头字符串 \tfor j := 0; j \u0026lt; len(cur); j++ { //每个字符的变化,之后再将 \tchangenum, _ := strconv.Atoi(cur[j : j+1]) nstr1, nstr2 := \u0026#34;\u0026#34;, \u0026#34;\u0026#34; if changenum == 9 { nstr1 = cur[:j] + strconv.Itoa(0) + cur[j+1:] } else { nstr1 = cur[:j] + strconv.Itoa(changenum+1) + cur[j+1:] } if changenum == 0 { nstr2 = cur[:j] + strconv.Itoa(9) + cur[j+1:] } else { nstr2 = cur[:j] + strconv.Itoa(changenum-1) + cur[j+1:] } if _, ok := visited[nstr1]; !ok { queue = append(queue, nstr1) visited[nstr1] = true } if _, ok := visited[nstr2]; !ok { queue = append(queue, nstr2) visited[nstr2] = true } } } queue = queue[size:] } return -1 }   ","date":"Jun 25","permalink":"https://hearecho.github.io/post/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-dag/","tags":["论文阅读","DAG","算法"],"title":"论文阅读 DAG"},{"categories":["blog"],"contents":"添加谷歌收录 添加谷歌收录的方式主要有四种方式：\n Google Analytics HTML file HTML tag Google Tag Manager Domain name provider  最简单的方式就是使用HTML TAG直接在模板head标签里面加上网站给出的验证标签即可。\ngoogle 分析 添加谷歌分析，可以获知自己网站的各项数据。同时也可以用于上述使得网站被谷歌收录。\n注册Google 分析   打开Google Analytics官网注册账户并添加自己的网站域名 打开主页，添加数据流，之后记录衡量ID。   修改配置文件 在config.toml中新建googleAnalytics参数并设置成自己的衡量ID\n1  googleAnalytics = \u0026#34;xx-xxxxxxxxx-x\u0026#34; # Enable Google Analytics by entering your tracking id   新建模板 在Hugo站点根目录下新建模板文件(./layouts/_internal/google_analytics_async.html)并添加如下代码.\n1 2 3 4 5 6 7 8 9  \u0026lt;!-- Global Site Tag (gtag.js) - Google Analytics --\u0026gt; \u0026lt;script async src=\u0026#34;https://www.googletagmanager.com/gtag/js?id={{ .Site.GoogleAnalytics }}\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag(\u0026#39;js\u0026#39;, new Date()); gtag(\u0026#39;config\u0026#39;, \u0026#39;{{ .Site.GoogleAnalytics }}\u0026#39;); \u0026lt;/script\u0026gt;   引用模板 在baseof.html基础模板文件中的head标签尾部添加如下代码, 这样站点发布到非Hugo Server后就会自动引用Google Analytics模板.或者也可以将上述的模板内容直接粘贴复制到baseof.html相应的位置。\n1 2 3 4 5  \u0026lt;head\u0026gt; {{- if not .Site.IsServer }} {{ template \u0026#34;_internal/google_analytics_async.html\u0026#34; . }} {{- end }} \u0026lt;/head\u0026gt;   每日一题 下一个排列 实现获取 下一个排列 的函数，算法需要将给定数字序列重新排列成字典序中下一个更大的排列。如果不存在下一个更大的排列，则将数字重新排列成最小的排列（即升序排列）。必须 原地 修改，只允许使用额外常数空间。\n 目的是寻求按照字典序来说，下一个排列，当然可以找到全部排列，但是不太靠谱。我们可以自己通过该排列的顺序，找到下一个排列。\n例如：\n[1,2,3]\n[1,3,2]\n[2,1,3]\n[2,3,1]\n[3,1,2]\n[3,2,1]\n所以我们的目标是将左边一个较小的数和右边的一个较大的数进行交换，如此下一个排列才会更大，同时由于不能打太多。同时我们要让这个「较小数」尽量靠右，而「较大数」尽可能小。当交换完成后，「较大数」右边的数需要按照升序重新排列。这样可以在保证新排列大于原来排列的情况下，使变大的幅度尽可能小。所以可以使用两次排序来确定两个数字的位置，然后进行交换.\n以排列 [4,5,2,6,3,1][4,5,2,6,3,1] 为例：\n我们能找到的符合条件的一对「较小数」与「较大数」的组合为 2 与 3，满足「较小数」尽量靠右，而「较大数」尽可能小。\n当我们完成交换后排列变为 [4,5,3,6,2,1][4,5,3,6,2,1]，此时我们可以重排「较小数」右边的序列，序列变为 [4,5,3,1,2,6][4,5,3,1,2,6]。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  func nextPermutation(nums []int) { // 先找到一个最小数，然后找到比这个较小数稍微大的较大数 \tn := len(nums) i := n - 2 //找到此时分割左右边的位置  // 也就是较小数尽可能的小 \tfor i \u0026gt;= 0 \u0026amp;\u0026amp; nums[i] \u0026gt;= nums[i+1] { i-- } if i \u0026gt;= 0 { j := n - 1 //找到较小数 \tfor j \u0026gt;= 0 \u0026amp;\u0026amp; nums[i] \u0026gt;= nums[j] { j-- } //交换 \tnums[i], nums[j] = nums[j], nums[i] } //之后反转右边的序列 \treverse(nums[i+1:]) } func reverse(a []int) { for i, n := 0, len(a); i \u0026lt; n/2; i++ { a[i], a[n-1-i] = a[n-1-i], a[i] } }   ","date":"Jun 24","permalink":"https://hearecho.github.io/post/hugo%E6%B7%BB%E5%8A%A0google%E6%94%B6%E5%BD%95/","tags":["Hugo","Google Console","杂记"],"title":"Hugo添加Google收录"},{"categories":["blog"],"contents":"简介  使用hugo搭建个人博客，并结合Github与Travis CI实现自动化集成部署。\n 本地运行 hugo下载（windows） 1  brew install hugo   检查可用之后，使用命令新建一个网站（不用新建文件夹，hugo会自动建立）：\n1 2  hugo new site your-site-name cd your-site-name   主题下载 主题是放到themes目录中，一般从hugo themes中找到想要的主题，下载到themes文件夹中。需要修改配置文件中相关配置，名字为文件夹名称。\n静态资源位置 静态资源位置一般是在网站目录下的static文件夹中\n添加文章 1 2 3  hugo new post/first.md # 该文件会在 content/post/目录下 # 执行编译之后，产生的文件在public目录下   运行 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  hugo server -D # 该条命令是本地测试运行，有可能markdown文件的draft标签为true，在真正编译的时候需要把true改为false # 不然不会显示 hugo # 就是编译命令 编译结果如下 Start building sites … | EN -------------------+----- Pages | 12 Paginator pages | 0 Non-page files | 0 Static files | 1 Processed images | 0 Aliases | 4 Sitemaps | 1 Cleaned | 0 Total in 76 ms   部署  部署我们一般使用两个仓库，一个仓库(blog)用于存放源文件，一个仓库(*.githu.io)用于存放生成的网站静态文件。\n存放源文件的仓库会在Travis中使用。\n 生成github token  前提是仓库已经全部建立，此时我们进入token，生成GITHUB_TOKEN。repo标签内全部选上即可。\n 结合Travis  前提是仓库已经全部建立，此时我们登录tracis ci，使用github进行登录，然后根据提示选择我们需要的仓库。也就是用于存放源文件的仓库。点击仓库右边的setting按钮。进入之后，在下方Environment Variables中添加变量名为GITHUB_TOKEN（这个随意，不过后面取得时候要注意保持一致）。\n 添加.travis.yml文件 这里我直接列举我自己得文件，对应改以下就好。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48  language:gogo:- \u0026#34;1.15\u0026#34;# 指定Golang 1.15# Specify which branches to build using a safelist# 分支白名单限制：只有 master 分支的提交才会触发构建branches:only:- masterinstall:# 安装最新的hugo- wget https://github.com/gohugoio/hugo/releases/download/v0.84.0/hugo_0.84.0_Linux-64bit.deb- sudo dpkg -i hugo*.deb# 安装主题- git clone https://github.com/WingLim/hugo-tania.git themes/tania --depth=1script:# 运行hugo命令- hugoafter_script:# 部署- cd ./public- git init- git config user.name \u0026#34;hearecho\u0026#34;- git config user.email \u0026#34;1540302560@qq.com\u0026#34;- git add .- git commit -m \u0026#34;Update Blog By TravisCI With Build $TRAVIS_BUILD_NUMBER\u0026#34;# Github Pages- git push --force --quiet \u0026#34;https://$GITHUB_TOKEN@${GH_REF}\u0026#34; master:masterenv:global:# Github Pages- GH_REF:github.com/hearecho/hearecho.github.iodeploy:provider:pages# 重要，指定这是一份github pages的部署配置skip-cleanup:true# 重要，不能省略local-dir:public# 静态站点文件所在目录# target-branch: master # 要将静态站点文件发布到哪个分支github-token:$GITHUB_TOKEN# 重要，$GITHUB_TOKEN是变量，需要在GitHub上申请、再到配置到Travis# fqdn: # 如果是自定义域名，此处要填keep-history:true# 是否保持target-branch分支的提交记录on:branch:master# 博客源码的分支  提交与检查 到此时，基本上工作已经完成。提交我们此次更改之后，travis会自动进行build，如果出错，应该是步骤问题。\nleetcode 每日一题  请实现一个函数，输入一个整数（以二进制串形式），输出该数二进制表示中 1 的个数。例如，把 9 表示成二进制是 1001，有 2 位是 1。因此，如果输入 9，则该函数输出 2。\n  解题思路，num与num-1在二进制位进行表示得时候，每次都会在第一个1出现得位置，变得不同，所以我们每次让num与num-1做与运算，直至num\u0026lt;=0\n 1 2 3 4 5 6 7 8  func hammingWeight(num uint32) int { x := 0 for num \u0026gt; 0 { num \u0026amp;= num-1 x++ } return x }   ","date":"Jun 23","permalink":"https://hearecho.github.io/post/hugo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","tags":["Hugo","Travis CI","杂记"],"title":"Hugo搭建个人博客"},{"categories":null,"contents":"","date":"Jun 23","permalink":"https://hearecho.github.io/articles/","tags":null,"title":"全部文章"}]